---
layout: "post" 
title: "Session 12: Text to image generation with diffusion models"
excerpt_separator: <!--more-->
categories: misc
project: false
active: false
---

# Text to image generation with diffusion models

This talk is slightly different because we will be talking about multiple papers, therefore there is no need to have read them beforehand.

In this session [Felipe Cruz](https://www.linkedin.com/in/afcruzs) will talk about how diffusion models work, using dalle-2 specifically as a use case and touch on the differences with newer models (imagen, stable Diffusion, parti, etc)

Felipe is a research engineer in Aleph Alpha working on novel methods to improve large pre-trained models, Both with and without scaling up models to billion of parameters and beyond. Previously he worked at Microsoft researching about scaling up multilingual models for machine translation, he also was part of the Cortana team. He got his master's in computer science from the University of Washington.



**Slides are here: [PDF](/assets/DM.pdf)****
