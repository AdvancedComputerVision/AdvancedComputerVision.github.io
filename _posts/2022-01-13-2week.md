---
layout: post
title: "Two-week challenge"
categories: misc
project: false
active: false
---

We took the challenge of reading one paper a day for two weeks and here is the list of the papers we all read. For the sake of exactness, it was around 1 paper per day on average and we didn’t need to read the same papers, some people shared some papers but in general, we were fully free to choose. 

After the 2 weeks, we made short meetings to share a very short summary of each of the papers

Here is the list of all papers discussed

1. [DROID-SLAM](https://github.com/princeton-vl/droid-slam)

2. [GitHub - ISEE-Technology/CamVox: [ICRA2021] A low-cost SLAM system based on camera and Livox lidar.](https://github.com/ISEE-Technology/CamVox "https://github.com/ISEE-Technology/CamVox")

3. A Review of Visual-LiDAR Fusion based Simultaneous Localization and Mapping

4. [Masked Autoencoders are Scalable Vision Learners](https://arxiv.org/abs/2111.06377)

5. [Blind Geometric Distortion Correction on Images Through Deep Learning](https://arxiv.org/abs/1909.03459)

6. [Self-supervised Monocular Depth Estimation with internal feature fusion](https://arxiv.org/abs/2110.09482)

7. [Recurrent Multi-View alignment network for unsupervised surface registration](https://arxiv.org/abs/2011.12104)

8. [Prototypical cross-attention network for multiple object tracking and segmentation](https://arxiv.org/abs/2106.11958)

9. [Nerf](https://www.matthewtancik.com/nerf)

10. [In-place scene labelling and understanding with implicit scene representation](https://arxiv.org/abs/2103.15875)

11. [Nerf in the wild](https://nerf-w.github.io/)

12. [Recurrent Multiframe single shot detector for video object detection](http://users.eecs.northwestern.edu/~asb479/papers/bmvc_2018.pdf)

13. [LoFTR: Detector-Free Local Feature Matching with Transformers](https://zju3dv.github.io/loftr/)

14. [Skip-Convolutions for Efficient Video Processing](https://arxiv.org/abs/2104.11487)

15. [One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing](https://nvlabs.github.io/face-vid2vid/)

16. [Probabilistic Future Prediction for Video Scene Understanding](https://arxiv.org/abs/2003.06409) 

17. [Urban Driving with Conditional Imitation Learning](https://arxiv.org/abs/1912.00177) 

18. [FIERY](https://wayve.ai/blog/fiery-future-instance-prediction-birds-eye-view/)

19. [Spatial Transformer Networks](https://arxiv.org/abs/1506.02025)

20. [ADOP](https://github.com/darglein/ADOP) 

21. [Variational End-to-End Navigation and Localization](https://arxiv.org/abs/1811.10119) 

22. [Neural Point-Based Graphics](https://arxiv.org/abs/1906.08240) 

23. ORB-SLAM2

24. [ORB-SLAM: a Versatile and Accurate Monocular SLAM System](https://arxiv.org/abs/1502.00956)

25. [Plen-octrees](https://alexyu.net/plenoctrees/)

26. [Lift, Splat, Shoot: Encoding Images from Arbitrary Camera Rigs by Implicitly Unprojecting to 3D](https://arxiv.org/abs/2008.05711)

27. [MonoLayout: Amodal scene layout from a single image](https://arxiv.org/abs/2002.08394)

28. [Orthographic Feature Transform for Monocular 3D Object Detection](https://arxiv.org/abs/1811.08188)

29. [The Transformer Model in Equations](https://johnthickstun.com/docs/transformers.pdf)

30. [Every Model Learned by Gradient Descent Is Approximately a Kernel Machine](https://arxiv.org/abs/2012.00152)

31. [MotionNet: Joint Perception and Motion Prediction for Autonomous Driving Based on Bird’s Eye View Maps](https://arxiv.org/abs/2003.06754)

32. [Why Having 10,000 Parameters in Your Camera Model is Better Than Twelve](https://arxiv.org/abs/1912.02908)

33. [ViViT: A Video Vision Transformer](https://arxiv.org/abs/2103.15691)

34. [Semantic-assisted 3D Normal Distributions Transform for scan registration in environments with limited structure](http://iliad-project.eu/wp-content/uploads/papers/iros_se_ndt.pdf)

35. Discrete Kalman Filter Tutorial

36. [Relational inductive biases, deep learning, and graph networks (in progress)](https://arxiv.org/abs/1806.01261)

37. [Inductive Biases for Deep Learning of Higher-Level Cognition.](https://arxiv.org/abs/2011.15091)

38. [On the Measure of Intelligence](https://arxiv.org/abs/1911.01547)

39. [Unsupervised Learning of Visual 3D Keypoints for Control](https://arxiv.org/abs/2106.07643)

40. [Transfer learning based few-shot classification using optimal transport mapping from preprocessed latent space of backbone neural network](https://arxiv.org/abs/2102.05176)

41. [Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://arxiv.org/abs/1703.03400)

42. [Prototypical Networks for Few-shot Learning](https://papers.nips.cc/paper/2017/hash/cb8da6767461f2812ae4290eac7cbc42-Abstract.html#:~:text=Prototypical%20Networks%20learn%20a%20metric,regime%2C%20and%20achieve%20excellent%20results.)